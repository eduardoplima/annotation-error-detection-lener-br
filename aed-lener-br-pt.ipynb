{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/eduardoplima/annotation-error-detection-lener-br/blob/main/aed-lener-br-pt.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7PC4E4Cm7rxn"
      },
      "source": [
        "# Detec√ß√£o de erros de anota√ß√£o no dataset LeNER-Br\n",
        "\n",
        "A detec√ß√£o de erros de anota√ß√£o (Annotation Error Detection) √© uma t√©cnica utilizada para identificar inconsist√™ncias ou r√≥tulos incorretos em conjuntos de dados anotados manualmente. Esses erros podem comprometer a qualidade dos modelos treinados sobre esses dados, em tarefas como o reconhecimento de entidades nomeadas. Ferramentas e m√©todos de detec√ß√£o buscam localizar essas falhas de forma automatizada, garantindo maior confiabilidade nos dados e melhor desempenho dos modelos.\n",
        "\n",
        "Nesse notebook analisaremos o dataset LeNER-Br com o objetivo de identificar poss√≠veis erros de anota√ß√£o utilizando a t√©cnica de confident learning, implementada pela biblioteca Cleanlab. Essa abordagem permite detectar inst√¢ncias rotuladas incorretamente com base nas previs√µes probabil√≠sticas de um classificador, como veremos no c√≥digo abaixo.\n",
        "\n",
        "O dataset LeNER-Br √© um corpus em portugu√™s voltado para o reconhecimento de entidades nomeadas (NER) em textos jur√≠dicos brasileiros. Desenvolvido por Luz et al. (2018), o LeNER-Br √© composto exclusivamente por documentos legais, como decis√µes judiciais e pareceres, coletados de diversos tribunais brasileiros. Ele foi manualmente anotado para identificar entidades como pessoas, organiza√ß√µes, localiza√ß√µes e express√µes temporais, al√©m de categorias jur√≠dicas espec√≠ficas como LEGISLA√á√ÉO e JURISPRUD√äNCIA, que n√£o s√£o comuns em outros corpora do portugu√™s. A descri√ß√£o completa do trabalho pode ser lida no artigo dispon√≠vel em https://teodecampos.github.io/LeNER-Br/luz_etal_propor2018.pdf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qGQ4_EVNU4vJ"
      },
      "source": [
        "# Configura√ß√£o do ambiente\n",
        "\n",
        "Instalamos a biblioteca Cleanlab, que ser√° empregada na aplica√ß√£o de t√©cnicas de confident learning para identificar poss√≠veis erros de anota√ß√£o no dataset LeNER-Br. Em seguida, importamos as bibliotecas necess√°rias para o restante da an√°lise e realizamos o download dos arquivos de treinamento e teste diretamente do reposit√≥rio oficial do LeNER-Br. Como os arquivos est√£o no formato CoNLL, que organiza os dados em colunas, √© necess√°rio convert√™-los para o formato BIO (Beginning, Inside, Outside), amplamente utilizado em tarefas de reconhecimento de entidades nomeadas, para facilitar o processamento subsequente.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "2S3U3tmOYnt4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eea92e24-d041-436e-a014-1f202520318f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: cleanlab in /usr/local/lib/python3.11/dist-packages (2.7.1)\n",
            "Requirement already satisfied: numpy~=1.22 in /usr/local/lib/python3.11/dist-packages (from cleanlab) (1.26.4)\n",
            "Requirement already satisfied: scikit-learn>=1.1 in /usr/local/lib/python3.11/dist-packages (from cleanlab) (1.6.1)\n",
            "Requirement already satisfied: tqdm>=4.53.0 in /usr/local/lib/python3.11/dist-packages (from cleanlab) (4.67.1)\n",
            "Requirement already satisfied: pandas>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from cleanlab) (2.2.2)\n",
            "Requirement already satisfied: termcolor>=2.4.0 in /usr/local/lib/python3.11/dist-packages (from cleanlab) (3.1.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.4.0->cleanlab) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.4.0->cleanlab) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.4.0->cleanlab) (2025.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.1->cleanlab) (1.15.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.1->cleanlab) (1.5.0)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.1->cleanlab) (3.6.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas>=1.4.0->cleanlab) (1.17.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install cleanlab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Zwf3b4wQNLzk"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import re\n",
        "import requests\n",
        "import zipfile\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "from cleanlab.filter import find_label_issues\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "9rNT2HBeMtm5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0a565614-0e1c-4dfd-d8fa-724577d9dcee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-05-17 18:06:48--  https://raw.githubusercontent.com/eduardoplima/aed-lener-br/refs/heads/main/leNER-Br/train/train.conll\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2142199 (2.0M) [text/plain]\n",
            "Saving to: ‚Äòtrain.conll.4‚Äô\n",
            "\n",
            "train.conll.4       100%[===================>]   2.04M  --.-KB/s    in 0.009s  \n",
            "\n",
            "2025-05-17 18:06:50 (215 MB/s) - ‚Äòtrain.conll.4‚Äô saved [2142199/2142199]\n",
            "\n",
            "--2025-05-17 18:06:50--  https://raw.githubusercontent.com/eduardoplima/aed-lener-br/refs/heads/main/leNER-Br/test/test.conll\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 438441 (428K) [text/plain]\n",
            "Saving to: ‚Äòtest.conll.4‚Äô\n",
            "\n",
            "test.conll.4        100%[===================>] 428.17K  --.-KB/s    in 0.005s  \n",
            "\n",
            "2025-05-17 18:06:51 (80.6 MB/s) - ‚Äòtest.conll.4‚Äô saved [438441/438441]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://raw.githubusercontent.com/eduardoplima/aed-lener-br/refs/heads/main/leNER-Br/train/train.conll\n",
        "!wget https://raw.githubusercontent.com/eduardoplima/aed-lener-br/refs/heads/main/leNER-Br/test/test.conll\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "ogVCKNIB6PyC"
      },
      "outputs": [],
      "source": [
        "NUM_FOLDS_CV = 5\n",
        "RANDOM_SEED = 43 # quase 42 üòÇ (e primo!)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "Oh7kICU9Y0rM"
      },
      "outputs": [],
      "source": [
        "def carregar_conll_lener(caminho_arquivo):\n",
        "    sentencas = []\n",
        "    tokens_sentenca_atual = []\n",
        "    etiquetas_sentenca_atual = []\n",
        "\n",
        "    with open(caminho_arquivo, 'r', encoding='utf-8') as f:\n",
        "        for linha in f:\n",
        "          linha = linha.strip()\n",
        "          if linha:\n",
        "              partes = linha.split()\n",
        "              if len(partes) >= 2:\n",
        "                  token = partes[0]\n",
        "                  etiqueta_ner = partes[-1]\n",
        "                  tokens_sentenca_atual.append(token)\n",
        "                  etiquetas_sentenca_atual.append(etiqueta_ner)\n",
        "              else:\n",
        "                  pass\n",
        "          else:\n",
        "              if tokens_sentenca_atual:\n",
        "                  sentencas.append(list(zip(tokens_sentenca_atual, etiquetas_sentenca_atual)))\n",
        "                  tokens_sentenca_atual = []\n",
        "                  etiquetas_sentenca_atual = []\n",
        "\n",
        "        if tokens_sentenca_atual:\n",
        "            sentencas.append(list(zip(tokens_sentenca_atual, etiquetas_sentenca_atual)))\n",
        "\n",
        "    return sentencas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "VLUrrOFwY8Ar",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "160c0199-2239-45e3-ce54-905337d5bd9e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Carregadas 7827 senten√ßas de train.conll.\n"
          ]
        }
      ],
      "source": [
        "sentencas_treino = carregar_conll_lener(\"train.conll\")\n",
        "print(f\"\\nCarregadas {len(sentencas_treino)} senten√ßas de train.conll.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0lLHkMYcTlva"
      },
      "source": [
        "A seguir vemos alguns exemplo de senten√ßas em formato BIO."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "mEZezenubD0n",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d438b614-30f7-4c49-f36e-c4da61f567c7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Exemplo de senten√ßa:\n",
            "V.v\tO\n",
            "APELA√á√ÉO\tO\n",
            "C√çVEL\tO\n",
            "-\tO\n",
            "NULIDADE\tO\n",
            "PROCESSUAL\tO\n",
            "-\tO\n",
            "INTIMA√á√ÉO\tO\n",
            "DO\tO\n",
            "MINIST√âRIO\tB-ORGANIZACAO\n",
            "P√öBLICO\tI-ORGANIZACAO\n",
            "-\tO\n",
            "INCAPAZ\tO\n",
            "ACOMPANHADA\tO\n",
            "DE\tO\n",
            "REPRESENTANTE\tO\n",
            "LEGAL\tO\n",
            "E\tO\n",
            "DE\tO\n",
            "ADVOGADO\tO\n",
            "-\tO\n",
            "EXERC√çCIO\tO\n",
            "DO\tO\n",
            "CONTRADIT√ìRIO\tO\n",
            "E\tO\n",
            "DA\tO\n",
            "AMPLA\tO\n",
            "DEFESA\tO\n",
            "-\tO\n",
            "AUS√äNCIA\tO\n",
            "DE\tO\n",
            "PREJU√çZOS\tO\n",
            "-\tO\n",
            "V√çCIO\tO\n",
            "AFASTADO\tO\n",
            "-\tO\n",
            "IMPROCED√äNCIA\tO\n",
            "DO\tO\n",
            "PEDIDO\tO\n",
            "-\tO\n",
            "INEXIST√äNCIA\tO\n",
            "DE\tO\n",
            "PROVA\tO\n",
            "QUANTO\tO\n",
            "AO\tO\n",
            "FATO\tO\n",
            "CONSTITUTIVO\tO\n",
            "DO\tO\n",
            "DIREITO\tO\n",
            ".\tO\n"
          ]
        }
      ],
      "source": [
        "print(\"\\nExemplo de senten√ßa:\")\n",
        "for token, label in sentencas_treino[5][-500:]:\n",
        "    print(f\"{token}\\t{label}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a2PxuZmG0hUc"
      },
      "source": [
        "# Extra√ß√£o de tokens\n",
        "\n",
        "Conforme vimos, as senten√ßas extra√≠das est√£o organizadas em tuplas de tokens e seus respectivos labels BIO. O objetivo √© extrair as features para cada token das nossas senten√ßas de treinamento utilizando um modelo BERT, via Hugging Face: nesse caso, o neuralmind/bert-large-portuguese-cased. Definimos explicitamente um tamanho m√°ximo de 512, tamanho padr√£o do modelo BERT escolhido, para evitar OverflowError.\n",
        "\n",
        "O processo seguido em cada senten√ßa √© o seguinte: primeiro, extra√≠mos os textos dos tokens. Em seguida, usamos o `tokenizer_hf` para converter esses textos em um formato que o modelo BERT entenda, especificando que a entrada j√° est√° dividida em palavras (is_split_into_words=True) e movendo os dados para o dispositivo de processamento (CPU ou GPU). Com os inputs prontos, passamos pelo model_hf para obter os \"hidden states\" da √∫ltima camada, que s√£o os embeddings contextuais para cada subpalavra gerada pelo tokenizador. Como o BERT trabalha com subpalavras, precisamos alinhar esses embeddings de volta aos nossos tokens originais. Para isso, utilizamos os word_ids fornecidos pelo tokenizador e, para cada token original, calculamos a m√©dia dos embeddings de suas subpalavras constituintes. Esses vetores m√©dios s√£o ent√£o adicionados √† nossa lista final features_tokens, representando numericamente cada palavra do nosso corpus.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "uuhNSeqc5SJo"
      },
      "outputs": [],
      "source": [
        "hf_model_name = \"neuralmind/bert-large-portuguese-cased\"\n",
        "\n",
        "tokenizer_hf = AutoTokenizer.from_pretrained(hf_model_name)\n",
        "model_hf = AutoModel.from_pretrained(hf_model_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C0Hdwt7Uau6N",
        "outputId": "bb61dacf-d4a1-477c-c887-08f14e22d7d4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Total de tokens nos dados de treinamento: 229277\n",
            "Labels √∫nicas do LeNER-Br: ['B-JURISPRUDENCIA', 'B-LEGISLACAO', 'B-LOCAL', 'B-ORGANIZACAO', 'B-PESSOA', 'B-TEMPO', 'I-JURISPRUDENCIA', 'I-LEGISLACAO', 'I-LOCAL', 'I-ORGANIZACAO', 'I-PESSOA', 'I-TEMPO', 'O']\n"
          ]
        }
      ],
      "source": [
        "todos_tokens = []\n",
        "todos_labels_ner = []\n",
        "ids_sentenca = []\n",
        "\n",
        "for i, sentenca in enumerate(sentencas_treino):\n",
        "  for token_text, ner_tag in sentenca:\n",
        "    todos_tokens.append(token_text)\n",
        "    todos_labels_ner.append(ner_tag)\n",
        "    ids_sentenca.append(i)\n",
        "\n",
        "print(f\"\\nTotal de tokens nos dados de treinamento: {len(todos_tokens)}\")\n",
        "print(f\"Labels √∫nicas do LeNER-Br: {sorted(list(set(todos_labels_ner)))}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Temos um total de 13 labels √∫nicas no nosso dataset. A seguir vemos uma explica√ß√£o do significado de cada uma delas:\n",
        "\n",
        "* **`B-JURISPRUDENCIA`**:\n",
        "    * **B**: Indica que este token √© o **in√≠cio** (Beginning) de uma entidade nomeada.\n",
        "    * **JURISPRUDENCIA**: Indica que a entidade nomeada √© do tipo \"Jurisprud√™ncia\". Refere-se a decis√µes judiciais, ac√≥rd√£os, s√∫mulas ou qualquer conjunto de interpreta√ß√µes das leis feitas pelos tribunais.\n",
        "    * *Exemplo*: No texto \"Conforme o **Ac√≥rd√£o** n¬∫ 123...\", \"Ac√≥rd√£o\" poderia ser `B-JURISPRUDENCIA`.\n",
        "\n",
        "* **`B-LEGISLACAO`**:\n",
        "    * **B**: In√≠cio da entidade.\n",
        "    * **LEGISLACAO**: Indica que a entidade nomeada √© do tipo \"Legisla√ß√£o\". Refere-se a leis, decretos, portarias, c√≥digos, constitui√ß√µes, etc.\n",
        "    * *Exemplo*: No texto \"A **Lei** n¬∫ 8.666/93...\", \"Lei\" poderia ser `B-LEGISLACAO`.\n",
        "\n",
        "* **`B-LOCAL`**:\n",
        "    * **B**: In√≠cio da entidade.\n",
        "    * **LOCAL**: Indica que a entidade nomeada √© um \"Local\". Pode ser uma cidade, estado, pa√≠s, endere√ßo, acidente geogr√°fico, etc.\n",
        "    * *Exemplo*: No texto \"Ele viajou para **Paris**...\", \"Paris\" seria `B-LOCAL`.\n",
        "\n",
        "* **`B-ORGANIZACAO`**:\n",
        "    * **B**: In√≠cio da entidade.\n",
        "    * **ORGANIZACAO**: Indica que a entidade nomeada √© uma \"Organiza√ß√£o\". Inclui empresas, institui√ß√µes governamentais, ONGs, times esportivos, etc.\n",
        "    * *Exemplo*: No texto \"O **Google** anunciou...\", \"Google\" seria `B-ORGANIZACAO`.\n",
        "\n",
        "* **`B-PESSOA`**:\n",
        "    * **B**: In√≠cio da entidade.\n",
        "    * **PESSOA**: Indica que a entidade nomeada √© uma \"Pessoa\". Refere-se a nomes de indiv√≠duos.\n",
        "    * *Exemplo*: No texto \"**Maria** Silva √© advogada...\", \"Maria\" seria `B-PESSOA`.\n",
        "\n",
        "* **`B-TEMPO`**:\n",
        "    * **B**: In√≠cio da entidade.\n",
        "    * **TEMPO**: Indica que a entidade nomeada √© uma refer√™ncia temporal. Pode ser uma data, hora, per√≠odo espec√≠fico (ex: \"s√©culo XXI\", \"pr√≥xima semana\").\n",
        "    * *Exemplo*: No texto \"A reuni√£o ser√° em **15 de maio**...\", \"15\" poderia ser `B-TEMPO`.\n",
        "\n",
        "* **`I-JURISPRUDENCIA`**:\n",
        "    * **I**: Indica que este token est√° **dentro** (Inside) de uma entidade do tipo \"Jurisprud√™ncia\" que j√° come√ßou. √â uma continua√ß√£o da entidade.\n",
        "    * *Exemplo*: No texto \"...o **Superior Tribunal** de Justi√ßa...\", se \"Superior\" foi `B-JURISPRUDENCIA` (ou `B-ORGANIZACAO` dependendo do esquema), \"Tribunal\" poderia ser `I-JURISPRUDENCIA` (ou `I-ORGANIZACAO`). No caso de um nome de jurisprud√™ncia longo, como \"S√∫mula **Vinculante n¬∫** 56\", \"Vinculante\", \"n¬∫\" e \"56\" seriam `I-JURISPRUDENCIA` se \"S√∫mula\" fosse `B-JURISPRUDENCIA`.\n",
        "\n",
        "* **`I-LEGISLACAO`**:\n",
        "    * **I**: Dentro de uma entidade do tipo \"Legisla√ß√£o\".\n",
        "    * *Exemplo*: No texto \"A **Lei de Licita√ß√µes**...\", se \"Lei\" foi `B-LEGISLACAO`, \"de\" e \"Licita√ß√µes\" seriam `I-LEGISLACAO`.\n",
        "\n",
        "* **`I-LOCAL`**:\n",
        "    * **I**: Dentro de uma entidade do tipo \"Local\".\n",
        "    * *Exemplo*: No texto \"Ele mora em **Nova York**...\", se \"Nova\" foi `B-LOCAL`, \"York\" seria `I-LOCAL`.\n",
        "\n",
        "* **`I-ORGANIZACAO`**:\n",
        "    * **I**: Dentro de uma entidade do tipo \"Organiza√ß√£o\".\n",
        "    * *Exemplo*: No texto \"O **Banco Central** do Brasil...\", se \"Banco\" foi `B-ORGANIZACAO`, \"Central\" seria `I-ORGANIZACAO`.\n",
        "\n",
        "* **`I-PESSOA`**:\n",
        "    * **I**: Dentro de uma entidade do tipo \"Pessoa\".\n",
        "    * *Exemplo*: No texto \"**Maria Joaquina** da Silva...\", se \"Maria\" foi `B-PESSOA`, \"Joaquina\" seria `I-PESSOA`.\n",
        "\n",
        "* **`I-TEMPO`**:\n",
        "    * **I**: Dentro de uma entidade do tipo \"Tempo\".\n",
        "    * *Exemplo*: No texto \"A reuni√£o ser√° em **15 de maio de 2025**...\", se \"15\" foi `B-TEMPO`, \"de\", \"maio\", \"de\" e \"2025\" seriam `I-TEMPO`.\n",
        "\n",
        "* **`O`**:\n",
        "    * **O**: Indica que o token est√° **fora** (Outside) de qualquer entidade nomeada. √â um token comum que n√£o faz parte de uma categoria de interesse espec√≠fica.\n",
        "    * *Exemplo*: No texto \"O gato **sentou** no tapete.\", \"sentou\" seria `O`.\n"
      ],
      "metadata": {
        "id": "QYIvrgZpnSTf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wx7eBlPHbxmf",
        "outputId": "16c525a4-5a96-4252-d5a9-1f5512f101ab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Usando device: cuda\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Usando device: {device}\")\n",
        "\n",
        "EFFECTIVE_MAX_LENGTH = 512\n",
        "\n",
        "model_hf.to(device)\n",
        "model_hf.eval()\n",
        "\n",
        "features_tokens = []\n",
        "\n",
        "for i_sent, dados_sentenca in enumerate(sentencas_treino):\n",
        "    textos_sentenca = [dado_token[0] for dado_token in dados_sentenca]\n",
        "\n",
        "    if not textos_sentenca:\n",
        "        # Senten√ßa vazia, pulamos\n",
        "        continue\n",
        "\n",
        "    inputs = tokenizer_hf(\n",
        "        textos_sentenca,\n",
        "        is_split_into_words=True,\n",
        "        return_tensors=\"pt\",\n",
        "        padding=\"longest\",\n",
        "        truncation=True,\n",
        "        max_length=EFFECTIVE_MAX_LENGTH\n",
        "    ).to(device)\n",
        "\n",
        "    word_ids = inputs.word_ids()\n",
        "    with torch.no_grad():\n",
        "        outputs = model_hf(**inputs)\n",
        "        last_hidden_state = outputs.last_hidden_state\n",
        "\n",
        "    token_subword_embeddings = [[] for _ in range(len(textos_sentenca))]\n",
        "\n",
        "    for subword_idx, original_word_idx in enumerate(word_ids):\n",
        "        if original_word_idx is not None: # Exclui tokens como [CLS], [SEP] ou tokens de padding\n",
        "            embedding = last_hidden_state[0, subword_idx, :]\n",
        "            token_subword_embeddings[original_word_idx].append(embedding)\n",
        "\n",
        "    sentence_token_features = []\n",
        "    for original_token_idx in range(len(textos_sentenca)):\n",
        "        if token_subword_embeddings[original_token_idx]:\n",
        "            stacked_embeddings = torch.stack(token_subword_embeddings[original_token_idx])\n",
        "            mean_embedding = torch.mean(stacked_embeddings, dim=0)\n",
        "            sentence_token_features.append(mean_embedding.cpu().numpy())\n",
        "        else:\n",
        "            sentence_token_features.append(np.zeros(model_hf.config.hidden_size))\n",
        "\n",
        "    features_tokens.extend(sentence_token_features)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BilVsoQncfZi",
        "outputId": "d838789f-8864-43ec-bd62-f84ca876e259"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Formato da matriz de caracter√≠sticas dos tokens: (229277, 1024)\n"
          ]
        }
      ],
      "source": [
        "features_tokens = np.array(features_tokens)\n",
        "print(f\"Formato da matriz de caracter√≠sticas dos tokens: {features_tokens.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BxJ31i-urTjS"
      },
      "source": [
        "# Treino do modelo\n",
        "\n",
        "Precisamos treinar um modelo para uso na biblioteca cleanlab. Inicialmente, os labels NER s√£o transformados utilizando a LabelEncoder, que transforma os r√≥tulos em n√∫meros para uso no modelo de Regress√£o Log√≠stica escolhido.\n",
        "\n",
        "No efetivo treino do nosso modelo dividimos nosso conjunto de dados (`features_tokens` e `labels_ner_codificados`) em duas partes: uma para treinamento (`X_treino`,`y_treino`) e outra para teste (`X_teste`, `y_teste`). Utilizamos 25% dos dados para o conjunto de teste e garantimos que a propor√ß√£o das diferentes classes de r√≥tulos NER seja mantida em ambas as divis√µes, gra√ßas ao par√¢metro stratify. Em seguida, preparamos um array chamado `probabilidades_preditas_teste`, que servir√° para armazenar as probabilidades de cada classe que o nosso modelo atribuir√° aos exemplos do conjunto de teste.\n",
        "\n",
        "Em seguida, definimos e treinamos o nosso modelo de classifica√ß√£o. Optamos por um SGDClassifier (Stochastic Gradient Descent Classifier). Ele funciona ajustando os par√¢metros de um modelo linear (neste caso, configurado para se comportar como uma Regress√£o Log√≠stica usando loss='log_loss') de forma iterativa, processando uma amostra por vez, fazendo com que seja r√°pido e escal√°vel. Ap√≥s treinar o modelo, n√≥s o utilizamos para prever as probabilidades das classes para o conjunto `X_teste`, armazenando-as em `probabilidades_preditas_teste`. Por fim, tamb√©m calculamos e exibimos a acur√°cia do modelo nesse conjunto de teste, comparando as predi√ß√µes com os r√≥tulos verdadeiros y_teste.\n",
        "\n",
        "Uma estrat√©gia de KFold com 5 folds foi utilizada para percorrer o dataset inteiro de modo separado e independente."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "EKa34kR3g95n"
      },
      "outputs": [],
      "source": [
        "label_encoder = LabelEncoder()\n",
        "labels_ner_codificados = label_encoder.fit_transform(todos_labels_ner)\n",
        "num_classes = len(label_encoder.classes_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eo0f5tOBhCC4",
        "outputId": "53a0b39c-e825-4601-ae40-c6604c4a15b6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Iniciando valida√ß√£o cruzada de 5 folds\n",
            "  Processando Fold 1/5...\n",
            "Modelo treinado.\n",
            "    Acur√°cia do Fold 1: 0.9680\n",
            "  Processando Fold 2/5...\n",
            "Modelo treinado.\n",
            "    Acur√°cia do Fold 2: 0.9734\n",
            "  Processando Fold 3/5...\n",
            "Modelo treinado.\n",
            "    Acur√°cia do Fold 3: 0.9696\n",
            "  Processando Fold 4/5...\n",
            "Modelo treinado.\n",
            "    Acur√°cia do Fold 4: 0.9720\n",
            "  Processando Fold 5/5...\n",
            "Modelo treinado.\n",
            "    Acur√°cia do Fold 5: 0.9719\n",
            "\n",
            "Coleta de probabilidades preditas fora da amostra finalizada.\n",
            "Formato da matriz de probabilidades_preditas: (229277, 13)\n"
          ]
        }
      ],
      "source": [
        "skf = StratifiedKFold(n_splits=NUM_FOLDS_CV, shuffle=True, random_state=RANDOM_SEED)\n",
        "probabilidades_preditas = np.zeros((len(features_tokens), num_classes))\n",
        "print(f\"\\nIniciando valida√ß√£o cruzada de {NUM_FOLDS_CV} folds\")\n",
        "\n",
        "for indice_fold, (indices_treino, indices_validacao) in enumerate(skf.split(features_tokens, labels_ner_codificados)):\n",
        "    print(f\"  Processando Fold {indice_fold + 1}/{NUM_FOLDS_CV}...\")\n",
        "    X_treino, X_validacao = features_tokens[indices_treino], features_tokens[indices_validacao]\n",
        "    y_treino, y_validacao = labels_ner_codificados[indices_treino], labels_ner_codificados[indices_validacao]\n",
        "\n",
        "    modelo = SGDClassifier(\n",
        "            loss='log_loss',\n",
        "            penalty='l2',\n",
        "            alpha=0.0001,\n",
        "            max_iter=1000,\n",
        "            tol=1e-3,\n",
        "            random_state=RANDOM_SEED,\n",
        "            class_weight='balanced',\n",
        "            learning_rate='optimal',\n",
        "            early_stopping=True,\n",
        "            n_iter_no_change=10,\n",
        "            validation_fraction=0.1\n",
        "        )\n",
        "\n",
        "\n",
        "    modelo.fit(X_treino, y_treino)\n",
        "    print(\"Modelo treinado.\")\n",
        "    probabilidades_preditas_fold = modelo.predict_proba(X_validacao)\n",
        "    probabilidades_preditas[indices_validacao] = probabilidades_preditas_fold\n",
        "\n",
        "    predicoes_fold = modelo.predict(X_validacao)\n",
        "    acuracia_fold = accuracy_score(y_validacao, predicoes_fold)\n",
        "    print(f\"    Acur√°cia do Fold {indice_fold + 1}: {acuracia_fold:.4f}\")\n",
        "\n",
        "print(\"\\nColeta de probabilidades preditas fora da amostra finalizada.\")\n",
        "print(f\"Formato da matriz de probabilidades_preditas: {probabilidades_preditas.shape}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4xu4qFf13xNY"
      },
      "source": [
        "# Problemas encontrados com o dataset\n",
        "\n",
        "Agora adentramos na aplica√ß√£o de fato das t√©cnicas de confident learning. Inicialmente, utilizamos a fun√ß√£o `find_label_issues` da biblioteca cleanlab para identificar tokens potencialmente mal rotulados em nosso dataset de NER. Passamos como entrada os label codificados (`labels_ner_codificados`) e as probabilidades previstas pelo modelo (`probabilidades_preditas`)."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(labels_ner_codificados),len(probabilidades_preditas)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S7-5LWpzcv2O",
        "outputId": "9d8df352-6694-4db7-d50a-74b6b8ee6bca"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(229277, 229277)"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "YcEe1bHWiMzE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1eff8717-6ff4-402c-8139-53bbab2f5cc7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Identificando problemas de rotulagem com cleanlab...\n",
            "Cleanlab identificou 2326 potenciais problemas de rotulagem.\n",
            "Isso representa 1.01% do total de tokens.\n"
          ]
        }
      ],
      "source": [
        "print(\"\\nIdentificando problemas de rotulagem com cleanlab...\")\n",
        "\n",
        "indices_problemas_rotulos = find_label_issues(\n",
        "        labels=labels_ner_codificados,\n",
        "        pred_probs=probabilidades_preditas,\n",
        "        return_indices_ranked_by='self_confidence'\n",
        "    )\n",
        "\n",
        "num_problemas_encontrados = len(indices_problemas_rotulos)\n",
        "print(f\"Cleanlab identificou {num_problemas_encontrados} potenciais problemas de rotulagem.\")\n",
        "percentual_problemas = (num_problemas_encontrados / len(todos_tokens)) * 100\n",
        "print(f\"Isso representa {percentual_problemas:.2f}% do total de tokens.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4AkTKFjaN84c"
      },
      "source": [
        "\n",
        "Em seguida, percorremos os √≠ndices dos tokens que apresentam poss√≠veis erros de anota√ß√£o no dataset de NER, comparando os r√≥tulos originais com os r√≥tulos sugeridos pelo modelo. Para cada token identificado como problem√°tico, recuperamos o token, o label e o transformamos para sua forma textual usando o label_encoder (m√©todo `inverse_transform`).\n",
        "\n",
        "Ent√ß√£o, identificamos o r√≥tulo predito pelo modelo com maior probabilidade e tamb√©m o decodificamos. Calculamos a confian√ßa do modelo no r√≥tulo original e recuperamos o identificador da senten√ßa a que o token pertence. Por fim, reunimos todas essas informa√ß√µes em uma lista de `dicts` (`problemas_para_revisao`).\n",
        "\n",
        "O `dict`  armazenado possui os seguintes campos que ser√£o √∫teis para nossa an√°lise posterior:\n",
        "\n",
        "* `indice_token_global`: posi√ß√£o do token em nossa lista com todos os tokens do nosso dataset\n",
        "* `id_sentenca`: identificador da frase problem√°tica\n",
        "* `rotulo_original`: o label que veio associado ao token no dataset\n",
        "* `rotulo_sugerido_pelo_modelo`: o label que nosso modelo sugere para o token\n",
        "* `confianca_modelo_no_rotulo_original`: a probabilidade que o modelo atribui ao r√≥tulo original. Valores baixos significam que nosso modelo n√£o tem muita confian√ßa que o label original est√° correto.\n",
        "* `contexto_sentenca_completa`: senten√ßa completa onde o token problem√°tico foi encontrado. Ser√° utilizado para visualizarmos os problemas que ser√£o tratados em um passo posterior.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "L8eNCoDMiPRU"
      },
      "outputs": [],
      "source": [
        "problemas_para_revisao = []\n",
        "for indice_token_global in indices_problemas_rotulos:\n",
        "    token_original = todos_tokens[indice_token_global]\n",
        "    rotulo_original_codificado = labels_ner_codificados[indice_token_global]\n",
        "    rotulo_original_str = label_encoder.inverse_transform([rotulo_original_codificado])[0]\n",
        "    rotulo_predito_codificado = np.argmax(probabilidades_preditas[indice_token_global])\n",
        "    rotulo_predito_str = label_encoder.inverse_transform([rotulo_predito_codificado])[0]\n",
        "\n",
        "    confianca_no_original = probabilidades_preditas[indice_token_global, rotulo_original_codificado]\n",
        "\n",
        "    id_sent = ids_sentenca[indice_token_global]\n",
        "\n",
        "    problemas_para_revisao.append({\n",
        "        \"indice_token_global\": indice_token_global,\n",
        "        \"id_sentenca\": id_sent,\n",
        "        \"token\": token_original,\n",
        "        \"rotulo_original\": rotulo_original_str,\n",
        "        \"rotulo_sugerido_pelo_modelo\": rotulo_predito_str,\n",
        "        \"confianca_modelo_no_rotulo_original\": confianca_no_original,\n",
        "        \"contexto_sentenca_completa\": sentencas_treino[id_sent]\n",
        "    })"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zfgj-RnWJB_U"
      },
      "source": [
        "Ordenamos os problemas pelas menores confian√ßas do modelo nos r√≥tulos fornecidos originalmente"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "haGoZq34xJUa"
      },
      "outputs": [],
      "source": [
        "problemas_para_revisao_ordenados = sorted(problemas_para_revisao, key=lambda x: x['confianca_modelo_no_rotulo_original'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_AMNDORdn3DF"
      },
      "source": [
        "E visualizamos os problemas encontrados. No la√ßo a seguir temos os 20 problemas com menor confianca do modelo no r√≥tulo original, ou seja, maior desconfian√ßa."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "ow2pyxdjzSEm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "264eadc1-138e-44d8-af5b-b7164e462ad4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Problema #1 (√çndice Global do Token: 138519)\n",
            "  ID da Senten√ßa: 4905\n",
            "  Token: 'artigo'\n",
            "  R√≥tulo Original: B-LOCAL\n",
            "  R√≥tulo Sugerido pelo Modelo: B-LEGISLACAO\n",
            "  Confian√ßa do Modelo no R√≥tulo Original: 0.0000\n",
            "  Contexto (¬±10 palavras): Logo(O) ,(O) tem-se(O) que(O) o(O) **artigo**(Original:B-LOCAL|Sugerido:B-LEGISLACAO)** 276(I-LOCAL) do(I-LOCAL) Decreto(I-LOCAL) n¬∫(I-LOCAL) 3.048/99(I-LOCAL) especificamente(O) fixa(O) o(O) dia(O) dois(O)\n",
            "\n",
            "Problema #2 (√çndice Global do Token: 122878)\n",
            "  ID da Senten√ßa: 4323\n",
            "  Token: 'Autos'\n",
            "  R√≥tulo Original: B-LOCAL\n",
            "  R√≥tulo Sugerido pelo Modelo: B-JURISPRUDENCIA\n",
            "  Confian√ßa do Modelo no R√≥tulo Original: 0.0000\n",
            "  Contexto (¬±10 palavras): 68(O) 3302-0444/0445(O) ,(O) Rio(B-LOCAL) Branco-AC(I-LOCAL) -(O) Mod(O) .(O) 500258(O) -(O) **Autos**(Original:B-LOCAL|Sugerido:B-JURISPRUDENCIA)** n.¬∫(I-LOCAL) 1002199-81.2017.8.01.0000/50000(I-LOCAL) ARA√öJO(O) ,(O) QUARTA(B-ORGANIZACAO) TURMA(I-ORGANIZACAO) ,(O) julgado(O) em(O) 09/05/2017(B-TEMPO)\n",
            "\n",
            "Problema #3 (√çndice Global do Token: 33548)\n",
            "  ID da Senten√ßa: 1067\n",
            "  Token: ','\n",
            "  R√≥tulo Original: I-LOCAL\n",
            "  R√≥tulo Sugerido pelo Modelo: O\n",
            "  Confian√ßa do Modelo no R√≥tulo Original: 0.0000\n",
            "  Contexto (¬±10 palavras): CONSTRU√á√ÉO(O) E(O) ALTERA(O) O(O) USO(O) DE(O) LOTES(O) NA(O) QUADRA(B-LOCAL) 1(I-LOCAL) **,**(Original:I-LOCAL|Sugerido:O)** DO(I-LOCAL) SETOR(I-LOCAL) DE(I-LOCAL) IND√öSTRIAS(I-LOCAL) GR√ÅFICAS(I-LOCAL) ,(O) NA(O) REGI√ÉO(B-LOCAL) ADMINISTRATIVA(I-LOCAL) DO(I-LOCAL)\n",
            "\n",
            "Problema #4 (√çndice Global do Token: 122879)\n",
            "  ID da Senten√ßa: 4323\n",
            "  Token: 'n.¬∫'\n",
            "  R√≥tulo Original: I-LOCAL\n",
            "  R√≥tulo Sugerido pelo Modelo: I-JURISPRUDENCIA\n",
            "  Confian√ßa do Modelo no R√≥tulo Original: 0.0000\n",
            "  Contexto (¬±10 palavras): 3302-0444/0445(O) ,(O) Rio(B-LOCAL) Branco-AC(I-LOCAL) -(O) Mod(O) .(O) 500258(O) -(O) Autos(B-LOCAL) **n.¬∫**(Original:I-LOCAL|Sugerido:I-JURISPRUDENCIA)** 1002199-81.2017.8.01.0000/50000(I-LOCAL) ARA√öJO(O) ,(O) QUARTA(B-ORGANIZACAO) TURMA(I-ORGANIZACAO) ,(O) julgado(O) em(O) 09/05/2017(B-TEMPO) ,(O)\n",
            "\n",
            "Problema #5 (√çndice Global do Token: 56502)\n",
            "  ID da Senten√ßa: 1863\n",
            "  Token: 'TAPE'\n",
            "  R√≥tulo Original: B-LOCAL\n",
            "  R√≥tulo Sugerido pelo Modelo: O\n",
            "  Confian√ßa do Modelo no R√≥tulo Original: 0.0000\n",
            "  Contexto (¬±10 palavras): COMPROMISSO(O) √â(O) COM(O) A(O) VERDADE(O) POR(O) ISSO(O) O(O) PSDB(B-ORGANIZACAO) 1(O) **TAPE**(Original:B-LOCAL|Sugerido:O)** VI(I-LOCAL) APOIA(O) IGOR(B-PESSOA) E(O) TECO(B-PESSOA) .(O)\n",
            "\n",
            "Problema #6 (√çndice Global do Token: 138520)\n",
            "  ID da Senten√ßa: 4905\n",
            "  Token: '276'\n",
            "  R√≥tulo Original: I-LOCAL\n",
            "  R√≥tulo Sugerido pelo Modelo: I-LEGISLACAO\n",
            "  Confian√ßa do Modelo no R√≥tulo Original: 0.0000\n",
            "  Contexto (¬±10 palavras): Logo(O) ,(O) tem-se(O) que(O) o(O) artigo(B-LOCAL) **276**(Original:I-LOCAL|Sugerido:I-LEGISLACAO)** do(I-LOCAL) Decreto(I-LOCAL) n¬∫(I-LOCAL) 3.048/99(I-LOCAL) especificamente(O) fixa(O) o(O) dia(O) dois(O) do(O)\n",
            "\n",
            "Problema #7 (√çndice Global do Token: 173708)\n",
            "  ID da Senten√ßa: 6020\n",
            "  Token: 'Penal'\n",
            "  R√≥tulo Original: I-TEMPO\n",
            "  R√≥tulo Sugerido pelo Modelo: I-LEGISLACAO\n",
            "  Confian√ßa do Modelo no R√≥tulo Original: 0.0000\n",
            "  Contexto (¬±10 palavras): 2.848(I-LEGISLACAO) ,(O) de(O) 7(B-TEMPO) de(I-TEMPO) dezembro(I-TEMPO) de(I-TEMPO) 1940(I-TEMPO) ((O) C√≥digo(B-TEMPO) **Penal**(Original:I-TEMPO|Sugerido:I-LEGISLACAO)** )(O) ,(O) passa(O) a(O) vigorar(O) com(O) as(O) seguintes(O) altera√ß√µes(O) :(O)\n",
            "\n",
            "Problema #8 (√çndice Global do Token: 45419)\n",
            "  ID da Senten√ßa: 1482\n",
            "  Token: '√∫nica'\n",
            "  R√≥tulo Original: I-LOCAL\n",
            "  R√≥tulo Sugerido pelo Modelo: I-ORGANIZACAO\n",
            "  Confian√ßa do Modelo no R√≥tulo Original: 0.0000\n",
            "  Contexto (¬±10 palavras): fls(O) .(O) 23-TJ(O) pelo(O) douto(O) Juiz(O) de(O) Direito(O) da(O) Vara(B-LOCAL) **√∫nica**(Original:I-LOCAL|Sugerido:I-ORGANIZACAO)** da(I-LOCAL) Comarca(I-LOCAL) de(I-LOCAL) Santa(I-LOCAL) Maria(I-LOCAL) do(I-LOCAL) Sua√ßu√≠/MG(I-LOCAL) ,(O) que(O) indeferiu(O)\n",
            "\n",
            "Problema #9 (√çndice Global do Token: 122880)\n",
            "  ID da Senten√ßa: 4323\n",
            "  Token: '1002199-81.2017.8.01.0000/50000'\n",
            "  R√≥tulo Original: I-LOCAL\n",
            "  R√≥tulo Sugerido pelo Modelo: I-JURISPRUDENCIA\n",
            "  Confian√ßa do Modelo no R√≥tulo Original: 0.0000\n",
            "  Contexto (¬±10 palavras): ,(O) Rio(B-LOCAL) Branco-AC(I-LOCAL) -(O) Mod(O) .(O) 500258(O) -(O) Autos(B-LOCAL) n.¬∫(I-LOCAL) **1002199-81.2017.8.01.0000/50000**(Original:I-LOCAL|Sugerido:I-JURISPRUDENCIA)** ARA√öJO(O) ,(O) QUARTA(B-ORGANIZACAO) TURMA(I-ORGANIZACAO) ,(O) julgado(O) em(O) 09/05/2017(B-TEMPO) ,(O) DJe(O)\n",
            "\n",
            "Problema #10 (√çndice Global do Token: 28356)\n",
            "  ID da Senten√ßa: 943\n",
            "  Token: 'Estrada'\n",
            "  R√≥tulo Original: I-LOCAL\n",
            "  R√≥tulo Sugerido pelo Modelo: B-LOCAL\n",
            "  Confian√ßa do Modelo no R√≥tulo Original: 0.0000\n",
            "  Contexto (¬±10 palavras): conformidade(O) com(O) as(O) seguintes(O) especifica√ß√µes(O) :(O) I(O) localiza√ß√£o(O) :(O) DF-001(B-LOCAL) **Estrada**(Original:I-LOCAL|Sugerido:B-LOCAL)** Parque(I-LOCAL) Contorno(I-LOCAL) EPCT(I-LOCAL) ,(O) km(O) 12,8(O) ,(O) na(O) Regi√£o(B-LOCAL) Administrativa(I-LOCAL)\n",
            "\n",
            "Problema #11 (√çndice Global do Token: 57701)\n",
            "  ID da Senten√ßa: 1912\n",
            "  Token: 'Cear√°'\n",
            "  R√≥tulo Original: B-LOCAL\n",
            "  R√≥tulo Sugerido pelo Modelo: I-ORGANIZACAO\n",
            "  Confian√ßa do Modelo no R√≥tulo Original: 0.0000\n",
            "  Contexto (¬±10 palavras): ementas(O) de(O) julgados(O) dos(O) TREs(O) de(O) Minas(B-LOCAL) Gerais(I-LOCAL) e(O) do(O) **Cear√°**(Original:B-LOCAL|Sugerido:I-ORGANIZACAO)** .(O)\n",
            "\n",
            "Problema #12 (√çndice Global do Token: 54465)\n",
            "  ID da Senten√ßa: 1795\n",
            "  Token: '27/02/2015'\n",
            "  R√≥tulo Original: B-PESSOA\n",
            "  R√≥tulo Sugerido pelo Modelo: B-TEMPO\n",
            "  Confian√ßa do Modelo no R√≥tulo Original: 0.0000\n",
            "  Contexto (¬±10 palavras): MOURA(I-PESSOA) ,(O) SEXTA(B-ORGANIZACAO) TURMA(I-ORGANIZACAO) ,(O) julgado(O) em(O) 09/12/2014(B-TEMPO) ,(O) DJe(O) **27/02/2015**(Original:B-PESSOA|Sugerido:B-TEMPO)** ;(O) HC(B-JURISPRUDENCIA) 312.391/SP(I-JURISPRUDENCIA) ,(O) Rel(O) .(O) Ministro(O) FELIX(B-PESSOA) FISCHER(I-PESSOA) ,(O)\n",
            "\n",
            "Problema #13 (√çndice Global do Token: 96444)\n",
            "  ID da Senten√ßa: 3240\n",
            "  Token: 'artigo'\n",
            "  R√≥tulo Original: B-ORGANIZACAO\n",
            "  R√≥tulo Sugerido pelo Modelo: B-LEGISLACAO\n",
            "  Confian√ßa do Modelo no R√≥tulo Original: 0.0000\n",
            "  Contexto (¬±10 palavras): n√£o(O) concretiza√ß√£o(O) ,(O) pelo(O) paciente(O) ,(O) do(O) tipo(O) previsto(O) no(O) **artigo**(Original:B-ORGANIZACAO|Sugerido:B-LEGISLACAO)** 187(I-ORGANIZACAO) do(I-ORGANIZACAO) C√≥digo(I-ORGANIZACAO) Penal(I-ORGANIZACAO) Militar(I-ORGANIZACAO) -(O) Crime(O) de(O) Deser√ß√£o(O) -(O)\n",
            "\n",
            "Problema #14 (√çndice Global do Token: 9642)\n",
            "  ID da Senten√ßa: 341\n",
            "  Token: 'per√≠odo'\n",
            "  R√≥tulo Original: B-TEMPO\n",
            "  R√≥tulo Sugerido pelo Modelo: O\n",
            "  Confian√ßa do Modelo no R√≥tulo Original: 0.0000\n",
            "  Contexto (¬±10 palavras): $(O) 30.000,00(O) ((O) trinta(O) mil(O) reais(O) )(O) ,(O) alusivos(O) o(O) **per√≠odo**(Original:B-TEMPO|Sugerido:O)** de(I-TEMPO) maio(I-TEMPO) a(I-TEMPO) novembro(I-TEMPO) de(I-TEMPO) 2014(I-TEMPO) ;(O) c(O) )(O) R(O)\n",
            "\n",
            "Problema #15 (√çndice Global do Token: 33464)\n",
            "  ID da Senten√ßa: 1066\n",
            "  Token: 'Federal.Por'\n",
            "  R√≥tulo Original: I-LOCAL\n",
            "  R√≥tulo Sugerido pelo Modelo: O\n",
            "  Confian√ßa do Modelo no R√≥tulo Original: 0.0000\n",
            "  Contexto (¬±10 palavras): iniciativa(O) do(O) processo(O) legislativo(O) compete(O) privativamente(O) ao(O) Governador(O) do(O) Distrito(B-LOCAL) **Federal.Por**(Original:I-LOCAL|Sugerido:O)** isso(O) mesmo(O) ,(O) demonstrado(O) que(O) a(O) iniciativa(O) das(O) leis(O) distritais(O)\n",
            "\n",
            "Problema #16 (√çndice Global do Token: 84104)\n",
            "  ID da Senten√ßa: 2801\n",
            "  Token: 'Porta-Avi√µes'\n",
            "  R√≥tulo Original: B-LOCAL\n",
            "  R√≥tulo Sugerido pelo Modelo: I-LOCAL\n",
            "  Confian√ßa do Modelo no R√≥tulo Original: 0.0000\n",
            "  Contexto (¬±10 palavras): ((O) ...(O) )(O) que(O) conheceu(O) o(O) Acusado(O) quando(O) serviu(O) no(O) **Porta-Avi√µes**(Original:B-LOCAL|Sugerido:I-LOCAL)** S√£o(I-LOCAL) Paulo(I-LOCAL) ;(O) ((O) ...(O) )(O) que(O) o(O) endere√ßo(O) do(O)\n",
            "\n",
            "Problema #17 (√çndice Global do Token: 138521)\n",
            "  ID da Senten√ßa: 4905\n",
            "  Token: 'do'\n",
            "  R√≥tulo Original: I-LOCAL\n",
            "  R√≥tulo Sugerido pelo Modelo: I-LEGISLACAO\n",
            "  Confian√ßa do Modelo no R√≥tulo Original: 0.0000\n",
            "  Contexto (¬±10 palavras): Logo(O) ,(O) tem-se(O) que(O) o(O) artigo(B-LOCAL) 276(I-LOCAL) **do**(Original:I-LOCAL|Sugerido:I-LEGISLACAO)** Decreto(I-LOCAL) n¬∫(I-LOCAL) 3.048/99(I-LOCAL) especificamente(O) fixa(O) o(O) dia(O) dois(O) do(O) m√™s(O)\n",
            "\n",
            "Problema #18 (√çndice Global do Token: 181082)\n",
            "  ID da Senten√ßa: 6176\n",
            "  Token: 'Autom√≥vel'\n",
            "  R√≥tulo Original: I-LOCAL\n",
            "  R√≥tulo Sugerido pelo Modelo: B-LOCAL\n",
            "  Confian√ßa do Modelo no R√≥tulo Original: 0.0000\n",
            "  Contexto (¬±10 palavras): -(O) S√£o(B-LOCAL) Sebasti√£o(I-LOCAL) ;(O) XXVII(O) -(O) SCIA(B-LOCAL) ((O) Cidade(B-LOCAL) do(I-LOCAL) **Autom√≥vel**(Original:I-LOCAL|Sugerido:B-LOCAL)** e(O) Estrutural(B-LOCAL) )(O) ;(O) XXVIII(O) -(O) SIA(B-LOCAL) e(O) Setores(O) Complementares(O)\n",
            "\n",
            "Problema #19 (√çndice Global do Token: 45418)\n",
            "  ID da Senten√ßa: 1482\n",
            "  Token: 'Vara'\n",
            "  R√≥tulo Original: B-LOCAL\n",
            "  R√≥tulo Sugerido pelo Modelo: I-ORGANIZACAO\n",
            "  Confian√ßa do Modelo no R√≥tulo Original: 0.0000\n",
            "  Contexto (¬±10 palavras): √†s(O) fls(O) .(O) 23-TJ(O) pelo(O) douto(O) Juiz(O) de(O) Direito(O) da(O) **Vara**(Original:B-LOCAL|Sugerido:I-ORGANIZACAO)** √∫nica(I-LOCAL) da(I-LOCAL) Comarca(I-LOCAL) de(I-LOCAL) Santa(I-LOCAL) Maria(I-LOCAL) do(I-LOCAL) Sua√ßu√≠/MG(I-LOCAL) ,(O) que(O)\n",
            "\n",
            "Problema #20 (√çndice Global do Token: 9667)\n",
            "  ID da Senten√ßa: 341\n",
            "  Token: 'per√≠odo'\n",
            "  R√≥tulo Original: B-TEMPO\n",
            "  R√≥tulo Sugerido pelo Modelo: O\n",
            "  Confian√ßa do Modelo no R√≥tulo Original: 0.0000\n",
            "  Contexto (¬±10 palavras): e(O) cinco(O) mil(O) reais(O) )(O) por(O) cada(O) m√™s(O) referente(O) ao(O) **per√≠odo**(Original:B-TEMPO|Sugerido:O)** de(I-TEMPO) novembro(I-TEMPO) de(I-TEMPO) 2014(I-TEMPO) outubro(I-TEMPO) de(I-TEMPO) 2015(I-TEMPO) ((O) data(O) da(O)\n",
            "\n",
            "Fim da exibi√ß√£o dos problemas.\n"
          ]
        }
      ],
      "source": [
        "for i, problema in enumerate(problemas_para_revisao_ordenados[:min(20, num_problemas_encontrados)]):\n",
        "    print(f\"\\nProblema #{i+1} (√çndice Global do Token: {problema['indice_token_global']})\")\n",
        "    print(f\"  ID da Senten√ßa: {problema['id_sentenca']}\")\n",
        "    print(f\"  Token: '{problema['token']}'\")\n",
        "    print(f\"  R√≥tulo Original: {problema['rotulo_original']}\")\n",
        "    print(f\"  R√≥tulo Sugerido pelo Modelo: {problema['rotulo_sugerido_pelo_modelo']}\")\n",
        "    print(f\"  Confian√ßa do Modelo no R√≥tulo Original: {problema['confianca_modelo_no_rotulo_original']:.4f}\")\n",
        "\n",
        "    tokens_tags_sentenca = problema['contexto_sentenca_completa'] # Lista de tuplas (token_texto, rotulo_original)\n",
        "\n",
        "    idx_primeiro_token_da_sentenca_no_dataset_global = -1\n",
        "    for idx_global, sent_id_global in enumerate(ids_sentenca):\n",
        "        if sent_id_global == problema['id_sentenca']:\n",
        "            idx_primeiro_token_da_sentenca_no_dataset_global = idx_global\n",
        "            break\n",
        "\n",
        "    posicao_token_na_sentenca = problema['indice_token_global'] - idx_primeiro_token_da_sentenca_no_dataset_global\n",
        "\n",
        "    if not (0 <= posicao_token_na_sentenca < len(tokens_tags_sentenca)) or \\\n",
        "       tokens_tags_sentenca[posicao_token_na_sentenca][0] != problema['token']:\n",
        "        for idx_sent, (tk_sent, _) in enumerate(tokens_tags_sentenca):\n",
        "            if tk_sent == problema['token']:\n",
        "                posicao_token_na_sentenca = idx_sent\n",
        "                break\n",
        "    janela_contexto = 10\n",
        "\n",
        "    inicio_ctx_ant = max(0, posicao_token_na_sentenca - janela_contexto)\n",
        "    contexto_anterior_dados = tokens_tags_sentenca[inicio_ctx_ant : posicao_token_na_sentenca]\n",
        "    contexto_anterior_formatado = [f\"{tk}({tag})\" for tk, tag in contexto_anterior_dados]\n",
        "\n",
        "    token_problematico_texto = problema['token']\n",
        "    rotulo_original_problematico = problema['rotulo_original']\n",
        "    rotulo_sugerido_problematico = problema['rotulo_sugerido_pelo_modelo']\n",
        "    token_destacado_str = f\"**{token_problematico_texto}**(Original:{rotulo_original_problematico}|Sugerido:{rotulo_sugerido_problematico})**\"\n",
        "\n",
        "    inicio_ctx_post = posicao_token_na_sentenca + 1\n",
        "    fim_ctx_post = min(len(tokens_tags_sentenca), inicio_ctx_post + janela_contexto)\n",
        "    contexto_posterior_dados = tokens_tags_sentenca[inicio_ctx_post : fim_ctx_post]\n",
        "    contexto_posterior_formatado = [f\"{tk}({tag})\" for tk, tag in contexto_posterior_dados]\n",
        "\n",
        "    partes_finais_contexto = []\n",
        "    if contexto_anterior_formatado:\n",
        "        partes_finais_contexto.append(\" \".join(contexto_anterior_formatado))\n",
        "\n",
        "    partes_finais_contexto.append(token_destacado_str)\n",
        "\n",
        "    if contexto_posterior_formatado:\n",
        "        partes_finais_contexto.append(\" \".join(contexto_posterior_formatado))\n",
        "\n",
        "    print(f\"  Contexto (¬±{janela_contexto} palavras): {' '.join(partes_finais_contexto)}\")\n",
        "\n",
        "print(\"\\nFim da exibi√ß√£o dos problemas.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nesse momento analisamos a sa√≠da do nosso modelo de confident learning. Vemos que nos primeiros problemas identificados o modelo acertadamente apontou erros na anota√ß√£o humano. Os problemas #1 e #2 tratam-se claramente de exemplos de legisla√ß√£o cadastrados erroneamente: \\*\\*artigo\\*\\*(Original:B-LOCAL|Sugerido:B-LEGISLACAO)\\*\\* 276(I-LOCAL) e  \\*\\*Autos\\*\\*(Original:B-LOCAL|Sugerido:B-JURISPRUDENCIA)\\*\\* n.¬∫(I-LOCAL) 1002199-81.2017.8.01.0000/50000(I-LOCAL).\n",
        "\n",
        "Todavia, h√° exemplos em que nosso modelo se confundiu ao apontar problemas em labels originais. No problema #3, a v√≠rgula no endere√ßo QUADRA(B-LOCAL) 1(I-LOCAL) \\*\\* , \\*\\*(Original:I-LOCAL|Sugerido:O)** DO(I-LOCAL) SETOR(I-LOCAL) DE(I-LOCAL) IND√öSTRIAS(I-LOCAL) GR√ÅFICAS(I-LOCAL) deve ser, de fato, considerada parte do label LOCAL.\n",
        "\n",
        "N√£o obstante o exemplo de engano cometido pelo modelo, percebe-se a efici√™ncia do modelo em identificar os labels problem√°ticos, atestando a efic√°cia da t√©cnica aplicada.\n",
        "\n"
      ],
      "metadata": {
        "id": "Iv_Az5ghjnRh"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8_k9BQoRN5Tz"
      },
      "source": [
        "# Conclus√£o\n",
        "\n",
        "Neste notebook, aplicamos t√©cnicas de Confident Learning utilizando a biblioteca cleanlab para detectar erros de anota√ß√£o no dataset LeNER-Br, amplamente utilizado em tarefas de Reconhecimento de Entidades Nomeadas (NER) em l√≠ngua portuguesa.\n",
        "\n",
        "Identificamos automaticamente diversos r√≥tulos inconsistentes entre as anota√ß√µes humanas e as previs√µes do modelo treinado, com base em crit√©rios de baixa confian√ßa. Foi poss√≠vel observar que muitos dos erros apontados pelo modelo indicavam de fato falhas de rotulagem no conjunto original, como a anota√ß√£o equivocada de express√µes legais e nomes de jurisprud√™ncia como localidades.\n",
        "\n",
        "Ainda que alguns falsos positivos tenham sido identificados ‚Äî como o caso da v√≠rgula no endere√ßo classificada incorretamente pelo modelo ‚Äî os resultados demonstram a relev√¢ncia da t√©cnica para auditoria e refinamento de datasets anotados manualmente.\n",
        "\n",
        "Conclu√≠mos que o uso de Confident Learning representa uma abordagem eficaz para a melhoria da qualidade de conjuntos de dados anotados, sobretudo em tarefas sens√≠veis como o NER jur√≠dico, onde erros de anota√ß√£o podem impactar significativamente o desempenho dos modelos.\n",
        "\n",
        "Como etapa futura, recomenda-se a aplica√ß√£o de t√©cnicas de retagging automatizado ou semiautom√°tico para corrigir os r√≥tulos identificados como problem√°ticos, utilizando as previs√µes de maior confian√ßa do modelo como sugest√£o inicial para revis√£o humana."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "provenance": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyM/RdvP+AB4I9n9iRUmRvEm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}